:ctime:    20220314200130
:END:
#+title: UMAP versus t-SNE
#+filetags: :unclean:

UMAP and [[denote:20220313T153430][t-SNE]] are very similar, but there are a couple of differences:
- t-SNE starts with a random initialization of the low-dimensional graph, but UMAP uses [[denote:20220313T161937][Spectral
  embedding]] to initialize the low-dimensional graph. Hence UMAP always starts with the same
  low-dimensional graph.
- t-SNE moves every point a little bit every iteration, but UMAP can move just a single point or a
  small subset of points every iteration, so it scales well with large datasets.

UMAP uses an exponentially decaying [[denote:20220314T195551][Similarity measure]] such that the function is always one for the
similarity to the nearest neighbour and such that the sum of all similarities is \(
log_2(\mathrm{\#NN}) \).

t-SNE on the other hand uses a Gaussian function to calculate the similarity. The nearest
neighbours parameter is similar to the perplexity parameter for t-SNE.

t-SNE makes things symmetric by averaging the similarities, but for UMAP we take \( (S_1 + S_2) -
S_1 S_2 \). This is the [[denote:20220314T200635][Fuzzy union operation]].

The low dimensional similarities follow a fixed [[denote:20220211T100816][t-distribution]]. For UMAP we have scores:

\[
\frac{1}{1 + \alpha \mathbf{d}^{2\beta}}
\]

By default \( \alpha = 1.577 \)  and \( \beta = 0.8951 \) whereas for t-SNE we always have \(
\alpha = \beta = 1 \). So UMAP gives us more control over how tightly we want to pack the
lower-dimensional points together.
