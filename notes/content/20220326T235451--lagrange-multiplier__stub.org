:ctime:    20220326235451
:END:
#+title: Lagrange multiplier
#+filetags: :stub:

If we want to find the maximum of some function \( f(\mathbf{x}) \) along some constraint \(
g(\mathbf{x}) = 0 \), then the gradient of \( f \) must be proportional to the gradient of \( g \).

Indeed, if this were not the case, we could move along \( g \) to increase the value of \( f \).

This means that at this maximal point, there must exist a \( \lambda \) such that

\[
\mathcal{L}(\mathbf{x}, \lambda) = f(\mathbf{x}) - \lambda g(\mathbf{x})
\]

satisfies \( \nabla \mathcal{L}(\mathbf{x}, \lambda) = 0 \).

In other words, we are now in the situation of a standard maximization problem. The additional
unknown \( \lambda \) may now be solved with the help of the constraint equation \( g(\mathbf{x}) = 0 \).

[[denote:20220401T204827][Envelope theorem]]
[[denote:20220401T230955][Interpretation of Lagrange multipliers]]
