:PROPERTIES:
:ID:       d91909b7-f1b4-446a-9ad3-7254415e75de
:mtime:    20220225223636
:ctime:    20220218210147
:END:
#+title: difference between independent and uncorrelated random variables

\begin{theorem}
Let \( X \) and \( Y \) be two independent random variables. Then \( X \) and \( Y \) are uncorrelated.
\end{theorem}

\begin{appendix}
If \( X \) and \( Y \) are independent, we have

\begin{eqnarray*}
\mathbb{E}[XY] & = & \int xy f_{X, Y}(x, y) \mathrm{d}x \mathrm{d}y \\
 & = & \int x f_X(x) \mathrm{d}x \int y f_Y(y) \mathbb{d}y \\
 & = & \mathbb{E}[X] \mathbb{E}[Y]
\end{eqnarray*}

This implies that

\begin{eqnarray*}
\mathrm{cov}(X, Y) & = & \mathbb{E}[XY] - \mathbb{E}[X] \mathbb{E}[Y] \\
& = & 0
\end{eqnarray*}

Hence the random variables are uncorrelated.

\end{appendix}

The contrary is not true. For example, pick \( X \sim \mathcal{N}(0, 1) \). Then \( X \) and \( X^2 \) are uncorrelated, since \( \mathrm{cov}(X, X^2) = \mathbb{E}[X^3] - \mathbb{E}[X] \mathbb{E}[X^2] = 0 \), but the variables are clearly not independent.
